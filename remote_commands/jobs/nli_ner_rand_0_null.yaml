
trainer: 'continuous_mlm'
args:
    seed: 0
    model_name: 'roberta-large'
    train: './data/ner_rand_0/train.jsonl'
    dev: './data/ner_rand_0/dev.jsonl'
    test: './data/ner_rand_0/test.jsonl'
    checklist: null
    template: '{sentence2} [P] {sentence1}'
    label_map: '{"entailment": "Yes", "not_entailment": "No"}'
    initial_trigger: []
    label_field: 'label'
    add_padding: False
    preprocessor: null
    evaluation_strategy: 'classification'
    decoding_strategy: null
    finetune_mode:
        - 'bitfit'
    evaluation_metric: 'accuracy'
    linear: False
    skip_train: False
    skip_eval: False
    skip_test: False
    bsz: 2
    epochs: 30
    disable_dropout: False
    clip: 1.0
    limit: null
    reduction_factor: 16
    l1decay: 0.0
    theta: 1.0e32
    force_overwrite: True
    quiet: False
    tmp: True
parameters:
    accumulation_steps: [4]
    lr: [1.0e-5]
    finetune_lr: [1.0e-5]

